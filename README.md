https://jackietseng.github.io/conference_call_for_paper/conferences-with-ccf.html

https://www.topbots.com/neurips-2020-covid-19-research-papers/?fbclid=IwAR3J8CDTLayz4GB324pFKBFCrUjcmKokeoJ8GHvuhi0iANRvbEFsBiHoy1A

https://venturebeat.com/2020/12/16/at-neurips-2020-researchers-proposed-faster-more-efficient-alternatives-to-backpropagation/?fbclid=IwAR3WohvqqTDgaPNN9XiHS-PTJB6d0xEJc_0wl_ba0Cr_rqr2OdlH2qhOThM

http://www.aitimes.kr/news/articleView.html?idxno=18700&fbclid=IwAR3iBZe2y8eBUmaN6_GOZMgLga968q_MCcvXtKafePUjn5cgy_h0oT-XJ6g

https://www.microsoft.com/en-us/research/blog/adversarial-machine-learning-and-instrumental-variables-for-flexible-causal-modeling/

https://arxiv.org/abs/2011.15091?fbclid=IwAR0r5FKZqR-MiA4qS2c9LTAqSEHIguYTMf1aqXLBVu7vr9fe61mxopbQS54

https://towardsdatascience.com/reformer-the-efficient-transformer-dd9830164703

[Lagrangian Neural Networks](https://arxiv.org/pdf/2003.04630.pdf)

https://github.com/kmario23/deep-learning-drizzle?fbclid=IwAR0969qFLTgHPjsI_3jrAxA_Abg4sWBXv27HQg2-FCSpSvfMsB7tTajnbSE

https://www.kaggle.com/andradaolteanu/pytorch-rnns-and-lstms-explained-acc-0-99/notebook


https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/understanding-causality-is-the-next-challenge-for-machine-learning?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed:+IeeeSpectrumFullText+(IEEE+Spectrum+Full+Text)

# Study Machine Learning


* Batch Normalization <br/>
https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/

* Optimizer <br/>
https://github.com/wonchul-kim/Machine_Learning/blob/master/deep%20learning/optimizers.ipynb

* cross-entropy <br/>
https://theeluwin.postype.com/post/6080524

* CNN <br/>
- CNN: https://seongkyun.github.io/study/2019/01/25/num_of_parameters/
- downsampling(pooling or subsampling):
   1. Max pooling
   2. Global average pooling
   3. convolutional layer with stride=2, kernel=3x3 .... better than others
- upsampling(unpooling):
   1. recover pooling: nearest neighbor unpooling, bed of nails unpooling, max unpooling
   2. using convolutional layer's stride: transpose convolution(deconvolution, fractionally-strided convolution, upconvolution, backward strided convolution)


https://analysisbugs.tistory.com/104
https://zzsza.github.io/data/2018/06/25/upsampling-with-transposed-convolution/


- dilated convolution
- separable convolution <br/>
https://zzsza.github.io/data/2018/02/23/introduction-convolution/
- deformable convolution

* mAP <br/>
https://bskyvision.com/465

* affine transformation <br/>
https://kr.mathworks.com/discovery/affine-transformation.html?requestedDomain=

* kernels for image processing <br/>
https://en.wikipedia.org/wiki/Kernel_(image_processing)

* hough transform <br/>
https://wkdtjsgur100.github.io/Hough-Transform/

* ATSS <br/>
 https://byeongjokim.github.io/posts/Bridging-the-Gap-Between-Anchor-based-and-Anchor-free-Detection-via-Adaptive-Training-Sample-Selection/
 
* BiT <br/>
https://developers-kr.googleblog.com/2020/06/open-sourcing-bit-exploring-large-scale.html

* maimum likelihood <br/>

* http://www.gisdeveloper.co.kr/?p=8443

* https://www.philgineer.com/2020/10/blog-post.html?fbclid=IwAR2IIJVAvyGR5JFhSXcicVZI8vbzEqTjfYSnnNm47SwuzFRGIRyAzh_MRLM



# Graph_Neural_Networks

## Lectures
* [ESE680](https://gnn.seas.upenn.edu/?fbclid=IwAR1Nvoxo5prQw_OVqxmWn8SowMX_1tfQApl3xVXGT3n2lMmf7FlOBc8Fs4o)

* [CS224W](http://web.stanford.edu/class/cs224w/index.html#schedule)


## References

* https://tobigs.gitbook.io/tobigs-graph-study/

* [A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)](https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3)

* [The graph neural network model](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf)

* [Graph Neural Networks: A Review of Methods and Applications](https://arxiv.org/pdf/1812.08434.pdf)

* https://www.youtube.com/watch?v=YL1jGgcY78U&list=PLSAJwo7mw8jn8iaXwT4MqLbZnS-LJwnBd&index=29&ab_channel=IdeaFactoryKAIST
